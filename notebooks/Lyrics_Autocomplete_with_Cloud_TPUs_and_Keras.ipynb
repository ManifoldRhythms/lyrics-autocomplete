{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lyrics Autocomplete with Cloud TPUs and Keras",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "N6ZDpd9XzFeN",
        "KRQ6Fjra3Ruq",
        "AbL6cqCl7hnt",
        "Bbb05dNynDrQ",
        "JwJ-eQgCWc1H"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "N6ZDpd9XzFeN"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "KUu4vOt5zI9d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "innBbve1LdjE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "edfbxDDh2AEs"
      },
      "cell_type": "markdown",
      "source": [
        "## Produce Lyrics with Cloud TPUs and Keras"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RNo1Vfghpa8j"
      },
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "This example uses [tf.keras](https://www.tensorflow.org/guide/keras) to build a *language model* and train it on a Cloud TPU. This language model predicts the next character of text given the text so far. The trained model can generate new snippets of text that read in a similar style to the text training data.\n",
        "\n",
        "The model trains for 10 epochs and completes in approximately 5 minutes.\n",
        "\n",
        "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dgAHfQtuhddd"
      },
      "cell_type": "markdown",
      "source": [
        "## Learning objectives\n",
        "\n",
        "In this Colab, you will learn how to:\n",
        "*   Build a two-layer, forward-LSTM model.\n",
        "*   Convert a `tf.keras` model to an equivalent TPU version and then use the standard Keras methods to train: `fit`, `predict`, and `evaluate`.\n",
        "*   Use the trained model to make predictions and generate your own Shakespeare-esque play.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QrprJD-R-410"
      },
      "cell_type": "markdown",
      "source": [
        "## Instructions"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kYxeFuKCUx9d"
      },
      "cell_type": "markdown",
      "source": [
        "TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Lvo0t7XVIkWZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Data, model, and training"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KRQ6Fjra3Ruq"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data\n",
        "\n",
        "Download *The Complete Works of William Shakespeare* as a single text file from [Project Gutenberg](https://www.gutenberg.org/). You use snippets from this file as the *training data* for the model. The *target* snippet is offset by one character."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "j8sIXh1DEDDd",
        "outputId": "3f7cad1d-3b5e-4e22-b788-9668afd41cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "cell_type": "code",
      "source": [
        "!wget --show-progress --continue -O /content/lyrics.txt https://storage.googleapis.com/mr-lyrics-autocomplete-data/lyrics.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-23 18:14:07--  https://storage.googleapis.com/mr-lyrics-autocomplete-data/lyrics.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.202.128, 2607:f8b0:4001:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7894384 (7.5M) [text/plain]\n",
            "Saving to: ‘/content/lyrics.txt’\n",
            "\n",
            "/content/lyrics.txt 100%[===================>]   7.53M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-01-23 18:14:08 (67.5 MB/s) - ‘/content/lyrics.txt’ saved [7894384/7894384]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AbL6cqCl7hnt"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the data generator"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E3V4V-Jxmuv3",
        "outputId": "a1c46018-b5f0-4452-87a4-35854bcd7be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import six\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "SHAKESPEARE_TXT = '/content/lyrics.txt'\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "def transform(txt, pad_to=None):\n",
        "  # drop any non-ascii characters\n",
        "  output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
        "  if pad_to is not None:\n",
        "    output = output[:pad_to]\n",
        "    output = np.concatenate([\n",
        "        np.zeros([pad_to - len(txt)], dtype=np.int32),\n",
        "        output,\n",
        "    ])\n",
        "  return output\n",
        "\n",
        "def training_generator(seq_len=100, batch_size=1024):\n",
        "  \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n",
        "  with tf.gfile.GFile(SHAKESPEARE_TXT, 'r') as f:\n",
        "    txt = f.read()\n",
        "\n",
        "  tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n",
        "  source = transform(txt)\n",
        "  while True:\n",
        "    offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n",
        "\n",
        "    # Our model uses sparse crossentropy loss, but Keras requires labels\n",
        "    # to have the same rank as the input logits.  We add an empty final\n",
        "    # dimension to account for this.\n",
        "    yield (\n",
        "        np.stack([source[idx:idx + seq_len] for idx in offsets]),\n",
        "        np.expand_dims(\n",
        "            np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]),\n",
        "            -1),\n",
        "    )\n",
        "\n",
        "six.next(training_generator(seq_len=10, batch_size=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Input text [7893815] \n",
            "\n",
            " baby im yours and ill be yours until the stars \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[101,  32, 121,  97, 108, 108,  32, 104, 101,  97]], dtype=int32),\n",
              " array([[[ 32],\n",
              "         [121],\n",
              "         [ 97],\n",
              "         [108],\n",
              "         [108],\n",
              "         [ 32],\n",
              "         [104],\n",
              "         [101],\n",
              "         [ 97],\n",
              "         [114]]], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Bbb05dNynDrQ"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the model\n",
        "\n",
        "The model is defined as a two-layer, forward-LSTM—with two changes from the `tf.keras` standard LSTM definition:\n",
        "\n",
        "1. Define the input `shape` of the model to comply with the [XLA compiler](https://www.tensorflow.org/performance/xla/)'s static shape requirement.\n",
        "2. Use `tf.train.Optimizer` instead of a standard Keras optimizer (Keras optimizer support is still experimental)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yLEM-fLJlEEt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 512\n",
        "\n",
        "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
        "  \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
        "  source = tf.keras.Input(\n",
        "      name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "  lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
        "  lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
        "  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
        "  model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
        "#   model_optimizer = tf.train.RMSPropOptimizer(learning_rate=0.01)\n",
        "  model_optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
        "  model.compile(\n",
        "      optimizer=model_optimizer,\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzBYDJI0_Tfm"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the model\n",
        "\n",
        "The `tf.contrib.tpu.keras_to_tpu_model` function converts a `tf.keras` model to an equivalent TPU version. You then use the standard Keras methods to train: `fit`, `predict`, and `evaluate`."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ExQ922tfzSGA",
        "outputId": "27db3ffc-3d06-4267-892c-73331b729a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "training_model = lstm_model(seq_len=100, batch_size=128, stateful=False)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    training_model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "tpu_model.load_weights('/content/lyrics_model.h5')\n",
        "\n",
        "# steps_per_epoch = DATA_LEN / (seq_len * batch_size)\n",
        "\n",
        "tpu_model.fit_generator(\n",
        "    training_generator(seq_len=100, batch_size=1024),\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        ")\n",
        "tpu_model.save_weights('/content/lyrics_model.h5', overwrite=True)\n",
        "\n",
        "elapsed = time.time() - start\n",
        "print(' {:.3f} minutes'.format(elapsed / 60))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.8.222.162:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7746463823360997788)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5895810441155439380)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 8970486844155138041)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 1196240473684309929)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7420280826846883607)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 660718350652434273)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11568057896446838443)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6624417795648083974)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16345395131179565799)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1092661703070112830)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5197736160469175851)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13981020397991571002)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:Input text [7893815] \n",
            "\n",
            " baby im yours and ill be yours until the stars \n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 100), dtype=tf.int32, name='seed_10'), TensorSpec(shape=(128, 100, 1), dtype=tf.float32, name='time_distributed_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 7.506659984588623 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "100/100 [==============================] - 40s 395ms/step - loss: 0.7412 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.7400 - sparse_categorical_accuracy: 0.7775\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.7410 - sparse_categorical_accuracy: 0.7770\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.7397 - sparse_categorical_accuracy: 0.7774\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7401 - sparse_categorical_accuracy: 0.7773\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7407 - sparse_categorical_accuracy: 0.7770\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.7379 - sparse_categorical_accuracy: 0.7782\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.7382 - sparse_categorical_accuracy: 0.7778\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.7377 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.7383 - sparse_categorical_accuracy: 0.7781\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            " 3.702 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JwJ-eQgCWc1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Eval the model"
      ]
    },
    {
      "metadata": {
        "id": "8uPN0EQtVvdu",
        "colab_type": "code",
        "outputId": "aba0a287-0d24-4915-8218-7b31ea5ee584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "loss, sparse_categorical_accuracy = tpu_model.evaluate_generator(\n",
        "    training_generator(seq_len=100, batch_size=1024),\n",
        "    steps=4\n",
        ")\n",
        "\n",
        "print('Testing set metrics:')\n",
        "print(\"\\tLoss: {:5.2f} value\".format(loss))\n",
        "print(\"\\tAccuracy: {:.2%} value\".format(sparse_categorical_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Input text [7893815] \n",
            "\n",
            " baby im yours and ill be yours until the stars \n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(128, 100), dtype=tf.int32, name='seed_10'), TensorSpec(shape=(128, 100, 1), dtype=tf.float32, name='time_distributed_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.172021150588989 secs\n",
            "Testing set metrics:\n",
            "\tLoss:  0.74 value\n",
            "\tAccuracy: 77.84% value\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TCBtcpZkykSf"
      },
      "cell_type": "markdown",
      "source": [
        "### Make predictions with the model\n",
        "\n",
        "Use the trained model to make predictions and generate your own Shakespeare-esque play.\n",
        "Start the model off with a *seed* sentence, then generate 250 characters from it. The model makes five predictions from the initial seed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tU7M-EGGxR3E",
        "outputId": "60100109-f1f3-4111-a023-363125ad0223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1872
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "PREDICT_LEN = 450\n",
        "\n",
        "# Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# time and predicting the next character.\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights('/content/lyrics_model.h5')\n",
        "\n",
        "# We seed the model with our initial string, copied BATCH_SIZE times\n",
        "\n",
        "# seed_txt = 'Looks it not like the king?  Verily, we must go! '\n",
        "# seed_txt = 'I am blind; the truth is screaming at me'\n",
        "seed_txt = 'Go.'\n",
        "# seed_txt = \"Cause everybody knows\"\n",
        "seed = transform(seed_txt)\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "\n",
        "# First, run the seed forward to prime the state of the model.\n",
        "prediction_model.reset_states()\n",
        "for i in range(len(seed_txt) - 1):\n",
        "  prediction_model.predict(seed[:, i:i + 1])\n",
        "\n",
        "# Now we can accumulate predictions!\n",
        "predictions = [seed[:, -1:]]\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_word = predictions[-1]\n",
        "  next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
        "  \n",
        "  # sample from our output distribution\n",
        "  next_idx = [\n",
        "      np.random.choice(256, p=next_probits[i])\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        "  \n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "  print('PREDICTION %d\\n\\n' % i)\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  generated = ''.join([chr(c) for c in p])\n",
        "  print(generated)\n",
        "  print()\n",
        "  assert len(generated) == PREDICT_LEN, 'Generated text too short'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION 0\n",
            "\n",
            "\n",
            ".\r\n",
            "Hit the time\n",
            "Do you know I bet they suckary torn between \n",
            "Hear the clothes, she goes out to school knew kany\r\n",
            "\r\n",
            "And I tried to death rather\r\n",
            "Free (One more)\n",
            "(Christmas)\n",
            "For you \n",
            "\n",
            "\n",
            "Ludal\n",
            "Letters (Hey)\n",
            "Don't get jack like a vegebr\r\n",
            "Why can't you be the one with our hearts believed\r\n",
            "Toucha\rne talkin' need a Thing\n",
            "Jottle\n",
            "\n",
            "I want you\n",
            "I'll taste, you see, you lead your aim\n",
            "I've draw this\n",
            "Seek and found in you, I see my reflect body \n",
            "\n",
            " i surre among \n",
            "\n",
            "PREDICTION 1\n",
            "\n",
            "\n",
            ".\r\n",
            "\r\n",
            "\r\n",
            "And do me down, too, boot, ring my room to get up, happiest that a willie\n",
            "Elis and patché\n",
            "\n",
            "Says \"ouns little in Junent\r\n",
            "\r\n",
            "Crazy, you oughta know that body sweet, and you should be\n",
            "and I need you\n",
            "I'd like to go gotta get rid\n",
            "But I take time, sing\n",
            "I fucked they 'cause i aim buh and I got for what Knoconsits but I feel the rain\n",
            "You think you mean the Summertimatized, sit up, I called, shut your hair down\n",
            "\n",
            "I still remember now, misled why do I\n",
            "\n",
            "PREDICTION 2\n",
            "\n",
            "\n",
            ".\r\n",
            "Gotta make it rain on the floor\r\n",
            "Tough the light let it shiny place\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Burning No lie, Oh nikit girls dime smiles\n",
            "Will pull me off with the man, my neighborite, don't really care so changing\n",
            "If it's hard to know oh\n",
            "\n",
            "\n",
            "Look, as I'd yeah, I ain't never wanted and you? \r\n",
            "Don't cry to me oh baby\n",
            "\n",
            "Oh, ooh one\r\n",
            "Touches the one that got so what I Feel I Feel for you\n",
            "\n",
            "\n",
            "Close to me i said be a chain on the train on you baby its yours i want to beill \n",
            "\n",
            "PREDICTION 3\n",
            "\n",
            "\n",
            "., ooh, night\n",
            "Merry hundrated \n",
            "\n",
            "\n",
            "Only enjoy\n",
            "Pretty please don't tell me now the band band on\n",
            "three batterand while could've made you wish, what more than i knew all the year of love\n",
            "You Indian-I'm your farm to be, strong, but broken heart's glowing 'll all \n",
            "Pulled from Minined \r\n",
            "I Twist the Lion Make My Thing I got One more Danger\n",
            "Say you that make me stuck up\n",
            "A message from What I've known, to me,\r\n",
            "Dont turn off the laid that I loved you\n",
            "True Do\n",
            "\n",
            "PREDICTION 4\n",
            "\n",
            "\n",
            ". \r\n",
            "\r\n",
            "SOwhere Her words we speak too?\n",
            "That's just as you're strong, oh I'll be your whole libera la I sure better hold me follow me for me,\r\n",
            "There loo youre gone?\n",
            "\n",
            "The very next day and the stars\n",
            "She's playing pleading from myself\n",
            "But now\r\n",
            "When the sun understands the word, so put it on, for such all it\r\n",
            "So whatever I sugar like Dear view I'll put Dats and maybe I made you used to put out the bathers\r\n",
            "Whip it with this like a manicohons\n",
            "She gon' \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}